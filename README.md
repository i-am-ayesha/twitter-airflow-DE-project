# Twitter Data Pipeline | End-to-End Data Engineering Project 🚀

## Introduction
This project focuses on building an end-to-end data pipeline using Airflow and Python to extract, transform, and store Twitter data. With seamless integration of Twitter API, EC2, Airflow, and Amazon S3, we automate the process from data extraction to storage.

## Architecture
📊 Real-Time Data Extraction → Transformation → Cloud Storage
![image](https://github.com/user-attachments/assets/8ed71b21-06ba-4875-bea6-7ca9fbe92e24)


## Technology Used
🔧 Programming Language: Python

☁️ Amazon Web Services (AWS):

EC2:
⚙️ Runs Airflow to automate and schedule the data pipeline tasks.

S3:
🛢️ Serves as the storage for the processed and transformed Twitter data.

💻 Apache Airflow:
⏰ Orchestrates the entire pipeline, ensuring smooth automation from data extraction to storage.

🐦 Twitter API:
📡 Fetches live Twitter data in real-time, powering the data pipeline with fresh content.

## Dataset Used
📅 Real-time tweets, including user information, tweet content, timestamps, and more, processed and stored for analytics.
