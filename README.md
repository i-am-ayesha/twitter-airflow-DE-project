# Twitter Data Pipeline | End-to-End Data Engineering Project ğŸš€

## Introduction
This project focuses on building an end-to-end data pipeline using Airflow and Python to extract, transform, and store Twitter data. With seamless integration of Twitter API, EC2, Airflow, and Amazon S3, we automate the process from data extraction to storage.

## Architecture
ğŸ“Š Real-Time Data Extraction â†’ Transformation â†’ Cloud Storage
![image](https://github.com/user-attachments/assets/8ed71b21-06ba-4875-bea6-7ca9fbe92e24)


## Technology Used
ğŸ”§ Programming Language: Python

â˜ï¸ Amazon Web Services (AWS):

EC2:
âš™ï¸ Runs Airflow to automate and schedule the data pipeline tasks.

S3:
ğŸ›¢ï¸ Serves as the storage for the processed and transformed Twitter data.

ğŸ’» Apache Airflow:
â° Orchestrates the entire pipeline, ensuring smooth automation from data extraction to storage.

ğŸ¦ Twitter API:
ğŸ“¡ Fetches live Twitter data in real-time, powering the data pipeline with fresh content.

## Dataset Used
ğŸ“… Real-time tweets, including user information, tweet content, timestamps, and more, processed and stored for analytics.
